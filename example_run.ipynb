{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab63f256-810b-459e-97bf-d239ba090dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce74c40e-d157-4462-afe2-178bc392156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT496\n",
      "Chunks shape: (75, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>course</th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>source</th>\n",
       "      <th>page</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8\\nModelling Long-Run Relationships in Finance...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and why it is essential that variables that ar...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>behaviour and properties\\n. To offer one illus...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          course  \\\n",
       "0  8\\nModelling Long-Run Relationships in Finance...  default_course   \n",
       "1  and why it is essential that variables that ar...  default_course   \n",
       "2  behaviour and properties\\n. To offer one illus...  default_course   \n",
       "\n",
       "    lecture_id                                             source  page  \\\n",
       "0  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     0   \n",
       "1  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     0   \n",
       "2  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     1   \n",
       "\n",
       "   chunk_id  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "candidates = [cwd, cwd.parent, cwd.parent.parent]\n",
    "\n",
    "project_root = None\n",
    "for c in candidates:\n",
    "    if (c / \"data\").exists() and (c / \"src\").exists():\n",
    "        project_root = c\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    project_root = cwd.parent\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "env_path = project_root / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "else:\n",
    "    print(\"WARNING: .env not found; set PERPLEXITY_API_KEY in environment manually.\")\n",
    "\n",
    "DATA_DIR = project_root / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "chunks_parquet = PROCESSED_DIR / \"lecture_chunks.parquet\"\n",
    "chunks_csv = PROCESSED_DIR / \"lecture_chunks.csv\"\n",
    "\n",
    "if chunks_parquet.exists():\n",
    "    chunks_df = pd.read_parquet(chunks_parquet)\n",
    "elif chunks_csv.exists():\n",
    "    chunks_df = pd.read_csv(chunks_csv)\n",
    "else:\n",
    "    raise FileNotFoundError(\"Run Notebook 1 to create lecture_chunks first.\")\n",
    "\n",
    "print(\"Chunks shape:\", chunks_df.shape)\n",
    "display(chunks_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d24788-28a4-4caf-9ef7-189d60aaa00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (75, 5000)\n"
     ]
    }
   ],
   "source": [
    "corpus = chunks_df[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b515cc-60c1-4d17-ac10-e323d635cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_local(query: str, k: int = 4) -> pd.DataFrame:\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix)[0]\n",
    "    k = min(k, len(sims))\n",
    "    top_indices = np.argsort(sims)[-k:][::-1]\n",
    "\n",
    "    rows = []\n",
    "    for rank, idx in enumerate(top_indices, start=1):\n",
    "        row = chunks_df.iloc[idx]\n",
    "        rows.append({\n",
    "            \"rank\": rank,\n",
    "            \"similarity\": float(sims[idx]),\n",
    "            \"lecture_id\": row.get(\"lecture_id\", \"\"),\n",
    "            \"page\": row.get(\"page\", None),\n",
    "            \"source\": row.get(\"source\", \"\"),\n",
    "            \"chunk_id\": row.get(\"chunk_id\", None),\n",
    "            \"text\": str(row[\"text\"]),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f12e218-8c61-45be-bfc6-8089fd1888f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_source_doc_id(row) -> str:\n",
    "    lecture_id = str(row.get(\"lecture_id\", \"\"))\n",
    "    page = row.get(\"page\", None)\n",
    "    chunk_id = row.get(\"chunk_id\", None)\n",
    "    return f\"{lecture_id}:page={page}:chunk={chunk_id}\"\n",
    "\n",
    "\n",
    "def extract_excerpt(text: str, max_chars: int = 400) -> str:\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    return text[: max_chars - 3] + \"...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a56afd-3f22-48cd-af4c-89d3c79e6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "class MCQQuestion(BaseModel):\n",
    "    id: str\n",
    "    stem: str\n",
    "    options: List[str]\n",
    "    correct_option_index: int\n",
    "    difficulty: str\n",
    "    topic: str\n",
    "    source_excerpt: str\n",
    "    source_doc_id: str\n",
    "\n",
    "class QuestionBundle(BaseModel):\n",
    "    mcqs: List[MCQQuestion] = []\n",
    "    short_answers: List[Dict[str, Any]] = []\n",
    "    concept_edges: List[Dict[str, Any]] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0decee-fab7-48ee-aad6-cdd2eacadfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mcq_prompt_for_llm(topic: str, k_context: int = 4) -> str:\n",
    "    ctx_df = semantic_search_local(topic, k=k_context)\n",
    "\n",
    "    if ctx_df.empty:\n",
    "        raise ValueError(\"No context found for this topic.\")\n",
    "\n",
    "    context_blocks = []\n",
    "    for _, row in ctx_df.iterrows():\n",
    "        source_id = build_source_doc_id(row)\n",
    "        excerpt = extract_excerpt(row[\"text\"])\n",
    "        block = f\"[SOURCE_ID: {source_id}]\\n{excerpt}\"\n",
    "        context_blocks.append(block)\n",
    "\n",
    "    context_text = \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI tutor helping a teacher create exam-style multiple-choice questions.\n",
    "\n",
    "Use ONLY the information in the CONTEXT below. Do not invent facts.\n",
    "\n",
    "CONTEXT:\n",
    "{context_text}\n",
    "\n",
    "TASK:\n",
    "Generate 3 clear, unambiguous multiple-choice questions about the topic: \"{topic}\".\n",
    "\n",
    "Rules:\n",
    "- Each question has exactly 4 options and exactly one correct option.\n",
    "- Options are mutually exclusive and not overlapping.\n",
    "- For each question, include:\n",
    "  - id (unique string)\n",
    "  - stem (question text)\n",
    "  - options (list of 4 strings)\n",
    "  - correct_option_index (0, 1, 2, or 3)\n",
    "  - difficulty (\"easy\", \"medium\", or \"hard\")\n",
    "  - topic (short topic label)\n",
    "  - source_excerpt (short quote/paraphrase from CONTEXT)\n",
    "  - source_doc_id (the SOURCE_ID you used)\n",
    "\n",
    "Output format:\n",
    "Return ONLY a JSON object with this structure:\n",
    "\n",
    "{{\n",
    "  \"mcqs\": [\n",
    "    {{\n",
    "      \"id\": \"string\",\n",
    "      \"stem\": \"string\",\n",
    "      \"options\": [\"string\", \"string\", \"string\", \"string\"],\n",
    "      \"correct_option_index\": 0,\n",
    "      \"difficulty\": \"easy|medium|hard\",\n",
    "      \"topic\": \"string\",\n",
    "      \"source_excerpt\": \"string\",\n",
    "      \"source_doc_id\": \"string\"\n",
    "    }}\n",
    "  ],\n",
    "  \"short_answers\": [],\n",
    "  \"concept_edges\": []\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON, no extra commentary.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3219ced0-7a41-4b01-82ee-eb2487379b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplx_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "if not pplx_key:\n",
    "    raise EnvironmentError(\"PERPLEXITY_API_KEY not set in environment or .env.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc494d58-648b-444d-bf86-71794e3a9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_perplexity_chat(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Call Perplexity chat completions API via HTTP and return the message content string.\n",
    "    \"\"\"\n",
    "    url = \"https://api.perplexity.ai/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {pplx_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-pro\",  \n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 1024,\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2381d3cc-8562-41df-b9b6-e4d31cb35163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_perplexity_for_mcqs(topic: str, k_context: int = 4) -> QuestionBundle:\n",
    "    prompt = build_mcq_prompt_for_llm(topic, k_context=k_context)\n",
    "    content = raw_perplexity_chat(prompt)\n",
    "\n",
    "    content_str = content.strip()\n",
    "    # Remove markdown code fences if present\n",
    "    if content_str.startswith(\"```\"):\n",
    "        # remove surrounding backticks / fences\n",
    "        content_str = content_str.strip(\"`\").strip()\n",
    "        # handle leading \"json\" language tag\n",
    "        if content_str.lower().startswith(\"json\"):\n",
    "            content_str = content_str[4:].strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(content_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Raw model output (truncated):\")\n",
    "        print(content_str[:1000])\n",
    "        raise RuntimeError(f\"Failed to parse JSON from model: {e}\")\n",
    "\n",
    "    try:\n",
    "        bundle = QuestionBundle(**data)\n",
    "    except ValidationError as e:\n",
    "        print(\"Parsed JSON but failed schema validation:\")\n",
    "        print(json.dumps(data, indent=2)[:1000])\n",
    "        raise\n",
    "\n",
    "    return bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a97a24-ed0d-4387-8568-1bfa3676ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received 3 MCQs from Perplexity.\n"
     ]
    }
   ],
   "source": [
    "topic = \"non-stationarity\"  \n",
    "\n",
    "bundle = call_perplexity_for_mcqs(topic, k_context=4)\n",
    "print(f\"Received {len(bundle.mcqs)} MCQs from Perplexity.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "224919bf-7ac0-421e-9868-7a6357b0cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stem</th>\n",
       "      <th>options</th>\n",
       "      <th>correct_option_index</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>topic</th>\n",
       "      <th>source_excerpt</th>\n",
       "      <th>source_doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nonstationarity_001</td>\n",
       "      <td>Which of the following is NOT one of the two f...</td>\n",
       "      <td>[Random walk model with drift, Trend-stationar...</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>Non-stationarity models</td>\n",
       "      <td>Two models that have been frequently used to c...</td>\n",
       "      <td>sample_data:page=3:chunk=8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nonstationarity_002</td>\n",
       "      <td>In the context of characteristic equations, wh...</td>\n",
       "      <td>[When the root of the characteristic equation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hard</td>\n",
       "      <td>Unit roots and stochastic non-stationarity</td>\n",
       "      <td>This is known as the unit root case, for the r...</td>\n",
       "      <td>sample_data:page=5:chunk=12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonstationarity_003</td>\n",
       "      <td>When a regression includes a linear trend term...</td>\n",
       "      <td>[Stochastic non-stationarity with a random wal...</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "      <td>Trend-stationary processes and detrending</td>\n",
       "      <td>If it is believed that only this class of non-...</td>\n",
       "      <td>sample_data:page=5:chunk=13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               stem  \\\n",
       "0  nonstationarity_001  Which of the following is NOT one of the two f...   \n",
       "1  nonstationarity_002  In the context of characteristic equations, wh...   \n",
       "2  nonstationarity_003  When a regression includes a linear trend term...   \n",
       "\n",
       "                                             options  correct_option_index  \\\n",
       "0  [Random walk model with drift, Trend-stationar...                     3   \n",
       "1  [When the root of the characteristic equation ...                     1   \n",
       "2  [Stochastic non-stationarity with a random wal...                     1   \n",
       "\n",
       "  difficulty                                       topic  \\\n",
       "0     medium                     Non-stationarity models   \n",
       "1       hard  Unit roots and stochastic non-stationarity   \n",
       "2     medium   Trend-stationary processes and detrending   \n",
       "\n",
       "                                      source_excerpt  \\\n",
       "0  Two models that have been frequently used to c...   \n",
       "1  This is known as the unit root case, for the r...   \n",
       "2  If it is believed that only this class of non-...   \n",
       "\n",
       "                 source_doc_id  \n",
       "0   sample_data:page=3:chunk=8  \n",
       "1  sample_data:page=5:chunk=12  \n",
       "2  sample_data:page=5:chunk=13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mcq_records = [q.model_dump() for q in bundle.mcqs]\n",
    "real_mcq_df = pd.DataFrame(mcq_records)\n",
    "display(real_mcq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a31e9c56-9801-45dc-94d8-a27c00c0a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved real MCQs to: C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT496\\data\\processed\\real_mcqs_non-stationarity.csv\n"
     ]
    }
   ],
   "source": [
    "safe_topic = topic.replace(\" \", \"_\")\n",
    "out_path = PROCESSED_DIR / f\"real_mcqs_{safe_topic}.csv\"\n",
    "real_mcq_df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(\"Saved real MCQs to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
