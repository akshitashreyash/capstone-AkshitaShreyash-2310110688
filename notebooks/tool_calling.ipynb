{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f977443-83d2-468a-9431-af6cc403c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2eb420-3857-4f6d-a045-ca916a34e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project root: C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT496\n",
      "Loaded chunks from C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT496\\data\\processed\\lecture_chunks.parquet\n",
      "Chunks DataFrame shape: (75, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>course</th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>source</th>\n",
       "      <th>page</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8\\nModelling Long-Run Relationships in Finance...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and why it is essential that variables that ar...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>behaviour and properties\\n. To offer one illus...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          course  \\\n",
       "0  8\\nModelling Long-Run Relationships in Finance...  default_course   \n",
       "1  and why it is essential that variables that ar...  default_course   \n",
       "2  behaviour and properties\\n. To offer one illus...  default_course   \n",
       "\n",
       "    lecture_id                                             source  page  \\\n",
       "0  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     0   \n",
       "1  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     0   \n",
       "2  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     1   \n",
       "\n",
       "   chunk_id  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "candidates = [cwd, cwd.parent, cwd.parent.parent]\n",
    "\n",
    "project_root = None\n",
    "for c in candidates:\n",
    "    if (c / \"data\").exists() and (c / \"src\").exists():\n",
    "        project_root = c\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    project_root = cwd.parent\n",
    "\n",
    "print(\"Detected project root:\", project_root)\n",
    "\n",
    "env_path = project_root / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "\n",
    "DATA_DIR = project_root / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "chunks_parquet = PROCESSED_DIR / \"lecture_chunks.parquet\"\n",
    "chunks_csv = PROCESSED_DIR / \"lecture_chunks.csv\"\n",
    "\n",
    "if chunks_parquet.exists():\n",
    "    chunks_df = pd.read_parquet(chunks_parquet)\n",
    "    print(f\"Loaded chunks from {chunks_parquet}\")\n",
    "elif chunks_csv.exists():\n",
    "    chunks_df = pd.read_csv(chunks_csv)\n",
    "    print(f\"Loaded chunks from {chunks_csv}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find lecture_chunks.parquet or lecture_chunks.csv in data/processed/. \"\n",
    "        \"Run Notebook 1 first.\"\n",
    "    )\n",
    "\n",
    "print(\"Chunks DataFrame shape:\", chunks_df.shape)\n",
    "display(chunks_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abeaeb75-b2ea-463d-978c-7f9adf914a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (75, 5000)\n"
     ]
    }
   ],
   "source": [
    "corpus = chunks_df[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52be7b8f-3052-4abd-8030-230505e53498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_local(query: str, k: int = 4):\n",
    "    if not isinstance(query, str) or not query.strip():\n",
    "        raise ValueError(\"Query must be a non-empty string.\")\n",
    "\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix)[0]\n",
    "\n",
    "    k = min(k, len(sims))\n",
    "    top_indices = np.argsort(sims)[-k:][::-1]\n",
    "\n",
    "    rows = []\n",
    "    for rank, idx in enumerate(top_indices, start=1):\n",
    "        row = chunks_df.iloc[idx]\n",
    "        rows.append({\n",
    "            \"rank\": rank,\n",
    "            \"similarity\": float(sims[idx]),\n",
    "            \"lecture_id\": row.get(\"lecture_id\", \"\"),\n",
    "            \"page\": row.get(\"page\", None),\n",
    "            \"source\": row.get(\"source\", \"\"),\n",
    "            \"chunk_id\": row.get(\"chunk_id\", None),\n",
    "            \"text\": str(row[\"text\"]),\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    return top_indices, result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d101e5-026e-4ae6-a50a-3670f4b30743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_search_lectures(topic: str, k: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Tool: search_lectures\n",
    "    Description: Given a topic string, return top-k relevant lecture chunks.\n",
    "    \"\"\"\n",
    "    _, ctx_df = semantic_search_local(topic, k=k)\n",
    "    return ctx_df.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb7bff6-95e5-413c-95c8-b64beec1baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_list_topics(min_count: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Tool: list_topics\n",
    "    Description: Heuristic topic list from lecture_id + frequent words in headings.\n",
    "    Currently returns counts per lecture_id; can be extended later.\n",
    "    \"\"\"\n",
    "    counts = chunks_df[\"lecture_id\"].value_counts().reset_index()\n",
    "    counts.columns = [\"lecture_id\", \"num_chunks\"]\n",
    "\n",
    "    if min_count is not None:\n",
    "        counts = counts[counts[\"num_chunks\"] >= min_count]\n",
    "\n",
    "    return counts.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cabbd18-8477-4b42-9962-bec9cc107298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_get_source_excerpt(lecture_id: str, page: int, n_chars: int = 300) -> str:\n",
    "    \"\"\"\n",
    "    Tool: get_source_excerpt\n",
    "    Description: Return a short excerpt for a given lecture_id + page combination.\n",
    "    \"\"\"\n",
    "    subset = chunks_df[\n",
    "        (chunks_df[\"lecture_id\"] == lecture_id) &\n",
    "        (chunks_df[\"page\"] == page)\n",
    "    ]\n",
    "\n",
    "    if subset.empty:\n",
    "        return \"\"\n",
    "\n",
    "    text = str(subset.iloc[0][\"text\"]).replace(\"\\n\", \" \").strip()\n",
    "    return text[:n_chars] + (\"...\" if len(text) > n_chars else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da1ce5ad-5bdb-4286-9787-3e46107dde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(tool_name: str, **kwargs) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple tool-calling router.\n",
    "    tool_name: one of \"search_lectures\", \"list_topics\", \"get_source_excerpt\".\n",
    "    kwargs: tool-specific arguments.\n",
    "    \"\"\"\n",
    "    if tool_name == \"search_lectures\":\n",
    "        topic = kwargs.get(\"topic\", \"\")\n",
    "        k = int(kwargs.get(\"k\", 5))\n",
    "        records = tool_search_lectures(topic, k=k)\n",
    "        return {\"tool\": tool_name, \"args\": {\"topic\": topic, \"k\": k}, \"result\": records}\n",
    "\n",
    "    if tool_name == \"list_topics\":\n",
    "        min_count = int(kwargs.get(\"min_count\", 3))\n",
    "        records = tool_list_topics(min_count=min_count)\n",
    "        return {\"tool\": tool_name, \"args\": {\"min_count\": min_count}, \"result\": records}\n",
    "\n",
    "    if tool_name == \"get_source_excerpt\":\n",
    "        lecture_id = kwargs.get(\"lecture_id\", \"\")\n",
    "        page = kwargs.get(\"page\", None)\n",
    "        n_chars = int(kwargs.get(\"n_chars\", 300))\n",
    "        excerpt = tool_get_source_excerpt(lecture_id, page, n_chars=n_chars)\n",
    "        return {\n",
    "            \"tool\": tool_name,\n",
    "            \"args\": {\"lecture_id\": lecture_id, \"page\": page, \"n_chars\": n_chars},\n",
    "            \"result\": excerpt,\n",
    "        }\n",
    "\n",
    "    raise ValueError(f\"Unknown tool name: {tool_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443bb02c-a26b-40f5-ba58-a78963be711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example topics / lectures:\n",
      "\n",
      "{'lecture_id': 'sample_data', 'num_chunks': 75}\n"
     ]
    }
   ],
   "source": [
    "topics_resp = call_tool(\"list_topics\", min_count=1)\n",
    "print(\"Example topics / lectures:\\n\")\n",
    "for row in topics_resp[\"result\"][:5]:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04e91bc-88d4-448b-a834-f24da9cd15a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search tool result for topic='probability distribution':\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>page</th>\n",
       "      <th>source</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.158606</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>12</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>30</td>\n",
       "      <td>(\\n8.37)\\nThe test statistics do not follow th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.121645</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>5</td>\n",
       "      <td>Figure 8.1\\n.\\nAs \\nFigure 8.1\\n shows, althou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.062212</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>6</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>16</td>\n",
       "      <td>process). Thus the series, ﾎ能\ny\\nt\\n would in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  similarity   lecture_id  page  \\\n",
       "0     1    0.158606  sample_data    12   \n",
       "1     2    0.121645  sample_data     1   \n",
       "2     3    0.062212  sample_data     6   \n",
       "\n",
       "                                              source  chunk_id  \\\n",
       "0  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...        30   \n",
       "1  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...         5   \n",
       "2  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...        16   \n",
       "\n",
       "                                                text  \n",
       "0  (\\n8.37)\\nThe test statistics do not follow th...  \n",
       "1  Figure 8.1\\n.\\nAs \\nFigure 8.1\\n shows, althou...  \n",
       "2  process). Thus the series, ﾎ能\ny\\nt\\n would in ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_topic = \"probability distribution\"  # adjust to your notes\n",
    "search_resp = call_tool(\"search_lectures\", topic=test_topic, k=3)\n",
    "\n",
    "print(f\"\\nSearch tool result for topic='{test_topic}':\\n\")\n",
    "search_df = pd.DataFrame(search_resp[\"result\"])\n",
    "display(search_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e99fd4b7-5a36-482b-b849-ead05618d502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First source excerpt:\n",
      "\n",
      "( 8.37) The test statistics do not follow the usual  t -distribution under the null hypothesis, since the null is one of non-stationarity, but rather they follow a non-standard distribution. Critical values are derived from simulations experiments in, for example, Fuller ( 1976 ); see also  Chapter ...\n"
     ]
    }
   ],
   "source": [
    "if search_resp[\"result\"]:\n",
    "    first = search_resp[\"result\"][0]\n",
    "    lec_id = first[\"lecture_id\"]\n",
    "    page = first[\"page\"]\n",
    "    excerpt_resp = call_tool(\"get_source_excerpt\", lecture_id=lec_id, page=page, n_chars=300)\n",
    "    print(\"\\nFirst source excerpt:\\n\")\n",
    "    print(excerpt_resp[\"result\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a7c252-8f75-4b44-aa88-24f8c34b6c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability distribution => 3 context chunks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>page</th>\n",
       "      <th>source</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.158606</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>12</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>30</td>\n",
       "      <td>(\\n8.37)\\nThe test statistics do not follow th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.121645</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>5</td>\n",
       "      <td>Figure 8.1\\n.\\nAs \\nFigure 8.1\\n shows, althou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.062212</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>6</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>16</td>\n",
       "      <td>process). Thus the series, ﾎ能\ny\\nt\\n would in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  similarity   lecture_id  page  \\\n",
       "0     1    0.158606  sample_data    12   \n",
       "1     2    0.121645  sample_data     1   \n",
       "2     3    0.062212  sample_data     6   \n",
       "\n",
       "                                              source  chunk_id  \\\n",
       "0  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...        30   \n",
       "1  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...         5   \n",
       "2  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...        16   \n",
       "\n",
       "                                                text  \n",
       "0  (\\n8.37)\\nThe test statistics do not follow th...  \n",
       "1  Figure 8.1\\n.\\nAs \\nFigure 8.1\\n shows, althou...  \n",
       "2  process). Thus the series, ﾎ能\ny\\nt\\n would in ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tool_guided_question_gen(topic: str, k: int = 4) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Example high-level function:\n",
    "    - Uses the search_lectures tool to get context.\n",
    "    - Returns context in a compact form that Notebook 4's graph can use.\n",
    "    \"\"\"\n",
    "    search_resp = call_tool(\"search_lectures\", topic=topic, k=k)\n",
    "    context_records = search_resp[\"result\"]\n",
    "\n",
    "    return {\n",
    "        \"topic\": topic,\n",
    "        \"context_chunks\": context_records,\n",
    "        \"n_context\": len(context_records),\n",
    "    }\n",
    "\n",
    "preview = tool_guided_question_gen(\"probability distribution\", k=3)\n",
    "print(preview[\"topic\"], \"=>\", preview[\"n_context\"], \"context chunks\")\n",
    "pd.DataFrame(preview[\"context_chunks\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
