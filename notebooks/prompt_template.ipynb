{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91d6137-74c2-4bd6-81f9-ce4442a17701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8cb9f6-d7dc-4ea6-8f75-c48b79841084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected project root: C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT496\n",
      "Loaded chunks from C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT496\\data\\processed\\lecture_chunks.parquet\n",
      "Chunks DataFrame shape: (75, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>course</th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>source</th>\n",
       "      <th>page</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8\\nModelling Long-Run Relationships in Finance...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and why it is essential that variables that ar...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>behaviour and properties\\n. To offer one illus...</td>\n",
       "      <td>default_course</td>\n",
       "      <td>sample_data</td>\n",
       "      <td>C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          course  \\\n",
       "0  8\\nModelling Long-Run Relationships in Finance...  default_course   \n",
       "1  and why it is essential that variables that ar...  default_course   \n",
       "2  behaviour and properties\\n. To offer one illus...  default_course   \n",
       "\n",
       "    lecture_id                                             source  page  \\\n",
       "0  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     0   \n",
       "1  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     0   \n",
       "2  sample_data  C:\\Users\\Admin\\OneDrive\\Desktop\\Capstone-MAT49...     1   \n",
       "\n",
       "   chunk_id  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "candidates = [cwd, cwd.parent, cwd.parent.parent]\n",
    "\n",
    "project_root = None\n",
    "for c in candidates:\n",
    "    if (c / \"data\").exists() and (c / \"src\").exists():\n",
    "        project_root = c\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    project_root = cwd.parent  # fallback\n",
    "\n",
    "print(\"Detected project root:\", project_root)\n",
    "\n",
    "env_path = project_root / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "else:\n",
    "    print(\"NOTE: .env not required for this notebook, but loaded if present.\")\n",
    "\n",
    "DATA_DIR = project_root / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "chunks_parquet = PROCESSED_DIR / \"lecture_chunks.parquet\"\n",
    "chunks_csv = PROCESSED_DIR / \"lecture_chunks.csv\"\n",
    "\n",
    "if chunks_parquet.exists():\n",
    "    chunks_df = pd.read_parquet(chunks_parquet)\n",
    "    print(f\"Loaded chunks from {chunks_parquet}\")\n",
    "elif chunks_csv.exists():\n",
    "    chunks_df = pd.read_csv(chunks_csv)\n",
    "    print(f\"Loaded chunks from {chunks_csv}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find lecture_chunks.parquet or lecture_chunks.csv in data/processed/. \"\n",
    "        \"Run Notebook 1 first.\"\n",
    "    )\n",
    "\n",
    "print(\"Chunks DataFrame shape:\", chunks_df.shape)\n",
    "display(chunks_df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb9ade-81c4-44bd-9e65-ebd6706d1635",
   "metadata": {},
   "source": [
    "# FROM 2ND STEP FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfbdd34-56c8-4380-925d-a59ec837691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape (rebuilt): (75, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "corpus = chunks_df[\"text\"].fillna(\"\").astype(str).tolist()\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"TF-IDF matrix shape (rebuilt):\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b04e515-845e-467e-8765-45ebc7ad56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_local(query: str, k: int = 4):\n",
    "    \"\"\"\n",
    "    Same semantic search helper as in Notebook 2.\n",
    "    \"\"\"\n",
    "    if not isinstance(query, str) or not query.strip():\n",
    "        raise ValueError(\"Query must be a non-empty string.\")\n",
    "\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix)[0]\n",
    "\n",
    "    k = min(k, len(sims))\n",
    "    top_indices = np.argsort(sims)[-k:][::-1]\n",
    "\n",
    "    rows = []\n",
    "    for rank, idx in enumerate(top_indices, start=1):\n",
    "        row = chunks_df.iloc[idx]\n",
    "        rows.append({\n",
    "            \"rank\": rank,\n",
    "            \"similarity\": float(sims[idx]),\n",
    "            \"lecture_id\": row.get(\"lecture_id\", \"\"),\n",
    "            \"page\": row.get(\"page\", None),\n",
    "            \"source\": row.get(\"source\", \"\"),\n",
    "            \"text\": str(row[\"text\"]),\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    return top_indices, result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab0e70d-cbe9-4b7d-9407-c4f724caef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCQQuestion(BaseModel):\n",
    "    \"\"\"Single multiple-choice question with one correct option.\"\"\"\n",
    "    id: str = Field(description=\"Unique ID for this question\")\n",
    "    stem: str = Field(description=\"The question text the student sees\")\n",
    "    options: List[str] = Field(description=\"List of answer choices\")\n",
    "    correct_option_index: int = Field(\n",
    "        description=\"Index of the correct option in the options list (0-based)\"\n",
    "    )\n",
    "    difficulty: str = Field(\n",
    "        description=\"One of: 'easy', 'medium', 'hard'\"\n",
    "    )\n",
    "    topic: str = Field(\n",
    "        description=\"Short topic label, e.g., 'linear_regression' or 'probability'\"\n",
    "    )\n",
    "    source_excerpt: str = Field(\n",
    "        description=\"Short excerpt from the lecture text that justifies the question\"\n",
    "    )\n",
    "    source_doc_id: str = Field(\n",
    "        description=\"Identifier of source doc/chunk, e.g., 'lecture_id:page:chunk_id'\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ShortAnswerQuestion(BaseModel):\n",
    "    \"\"\"Short-answer question and ideal answer.\"\"\"\n",
    "    id: str\n",
    "    question: str\n",
    "    ideal_answer: str\n",
    "    difficulty: str\n",
    "    topic: str\n",
    "    source_excerpt: str\n",
    "    source_doc_id: str\n",
    "\n",
    "\n",
    "class ConceptMapEdge(BaseModel):\n",
    "    \"\"\"Directed edge between two related concepts for concept-maps.\"\"\"\n",
    "    id: str\n",
    "    source_concept: str = Field(description=\"Starting concept (node A)\")\n",
    "    target_concept: str = Field(description=\"Related concept (node B)\")\n",
    "    relation: str = Field(\n",
    "        description=\"Short phrase describing relation, e.g., 'causes', 'depends on'\"\n",
    "    )\n",
    "    topic: str\n",
    "    source_excerpt: str\n",
    "    source_doc_id: str\n",
    "\n",
    "\n",
    "class QuestionBundle(BaseModel):\n",
    "    \"\"\"Container for batches of generated questions from one prompt.\"\"\"\n",
    "    mcqs: List[MCQQuestion] = []\n",
    "    short_answers: List[ShortAnswerQuestion] = []\n",
    "    concept_edges: List[ConceptMapEdge] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88cd487d-6037-47e0-83bd-e9fa625d69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_source_doc_id(row) -> str:\n",
    "    lecture_id = str(row.get(\"lecture_id\", \"\"))\n",
    "    page = row.get(\"page\", None)\n",
    "    chunk_id = row.get(\"chunk_id\", None)\n",
    "    return f\"{lecture_id}:page={page}:chunk={chunk_id}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d6cce7-178e-40f5-bd08-2565952d5eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_excerpt(text: str, max_chars: int = 400) -> str:\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    return text[: max_chars - 3] + \"...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9755a8d1-50fa-4379-b14b-f2591f51b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mcq_prompt(topic: str, k_context: int = 4) -> str:\n",
    "    \"\"\"\n",
    "    Build an MCQ-generation prompt using top-k retrieved chunks for a topic.\n",
    "    \"\"\"\n",
    "    _, ctx_df = semantic_search_local(topic, k=k_context)\n",
    "\n",
    "    context_blocks = []\n",
    "    for _, row in ctx_df.iterrows():\n",
    "        source_id = build_source_doc_id(row)\n",
    "        excerpt = extract_excerpt(row[\"text\"])\n",
    "        block = f\"[SOURCE_ID: {source_id}]\\n{excerpt}\"\n",
    "        context_blocks.append(block)\n",
    "\n",
    "    context_text = \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI tutor helping a teacher create exam-style multiple-choice questions.\n",
    "\n",
    "Use ONLY the information in the CONTEXT below. Do not invent facts.\n",
    "\n",
    "CONTEXT:\n",
    "{context_text}\n",
    "\n",
    "TASK:\n",
    "Generate 3 clear, unambiguous multiple-choice questions about the topic: \"{topic}\".\n",
    "\n",
    "Rules:\n",
    "- Each question must have exactly 4 options.\n",
    "- Exactly ONE option must be correct.\n",
    "- Options must be mutually exclusive; avoid \"all of the above\".\n",
    "- Tag each question with difficulty: \"easy\", \"medium\", or \"hard\".\n",
    "- For each question, include:\n",
    "  - a unique id string\n",
    "  - the question stem\n",
    "  - the 4 options\n",
    "  - correct_option_index (0, 1, 2, or 3)\n",
    "  - topic (short topic label)\n",
    "  - source_excerpt: a short quotation or paraphrase from CONTEXT that justifies the question\n",
    "  - source_doc_id: the SOURCE_ID of the chunk you used\n",
    "\n",
    "Output format:\n",
    "Return a JSON object that matches this Pydantic model:\n",
    "\n",
    "{{\n",
    "  \"mcqs\": [\n",
    "    {{\n",
    "      \"id\": \"string\",\n",
    "      \"stem\": \"string\",\n",
    "      \"options\": [\"string\", \"string\", \"string\", \"string\"],\n",
    "      \"correct_option_index\": 0,\n",
    "      \"difficulty\": \"easy|medium|hard\",\n",
    "      \"topic\": \"string\",\n",
    "      \"source_excerpt\": \"string\",\n",
    "      \"source_doc_id\": \"string\"\n",
    "    }}\n",
    "  ],\n",
    "  \"short_answers\": [],\n",
    "  \"concept_edges\": []\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON, no extra text.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4783de79-5eac-45dd-a96f-82bcf77c3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_short_answer_prompt(topic: str, k_context: int = 4) -> str:\n",
    "    _, ctx_df = semantic_search_local(topic, k=k_context)\n",
    "\n",
    "    context_blocks = []\n",
    "    for _, row in ctx_df.iterrows():\n",
    "        source_id = build_source_doc_id(row)\n",
    "        excerpt = extract_excerpt(row[\"text\"])\n",
    "        block = f\"[SOURCE_ID: {source_id}]\\n{excerpt}\"\n",
    "        context_blocks.append(block)\n",
    "\n",
    "    context_text = \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI tutor generating short-answer questions for students.\n",
    "\n",
    "Use ONLY the information in the CONTEXT below.\n",
    "\n",
    "CONTEXT:\n",
    "{context_text}\n",
    "\n",
    "TASK:\n",
    "Generate 3 short-answer questions about the topic: \"{topic}\".\n",
    "\n",
    "Rules:\n",
    "- Each question should be answerable in 1-3 sentences.\n",
    "- Avoid \"prove that\" or very open-ended questions.\n",
    "- For each question, include:\n",
    "  - id\n",
    "  - question\n",
    "  - ideal_answer\n",
    "  - difficulty (\"easy\", \"medium\", \"hard\")\n",
    "  - topic\n",
    "  - source_excerpt\n",
    "  - source_doc_id\n",
    "\n",
    "Output format:\n",
    "Return a JSON object matching this structure:\n",
    "\n",
    "{{\n",
    "  \"mcqs\": [],\n",
    "  \"short_answers\": [\n",
    "    {{\n",
    "      \"id\": \"string\",\n",
    "      \"question\": \"string\",\n",
    "      \"ideal_answer\": \"string\",\n",
    "      \"difficulty\": \"easy|medium|hard\",\n",
    "      \"topic\": \"string\",\n",
    "      \"source_excerpt\": \"string\",\n",
    "      \"source_doc_id\": \"string\"\n",
    "    }}\n",
    "  ],\n",
    "  \"concept_edges\": []\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5179d8eb-06cd-4bf5-92ae-a3331dc17f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_concept_map_prompt(topic: str, k_context: int = 4) -> str:\n",
    "    _, ctx_df = semantic_search_local(topic, k=k_context)\n",
    "\n",
    "    context_blocks = []\n",
    "    for _, row in ctx_df.iterrows():\n",
    "        source_id = build_source_doc_id(row)\n",
    "        excerpt = extract_excerpt(row[\"text\"])\n",
    "        block = f\"[SOURCE_ID: {source_id}]\\n{excerpt}\"\n",
    "        context_blocks.append(block)\n",
    "\n",
    "    context_text = \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant extracting concept-map relations from lecture text.\n",
    "\n",
    "Use ONLY the information in the CONTEXT below.\n",
    "\n",
    "CONTEXT:\n",
    "{context_text}\n",
    "\n",
    "TASK:\n",
    "Identify 5 important relationships between concepts related to the topic \"{topic}\".\n",
    "\n",
    "Each relationship should be represented as a directed edge:\n",
    "\n",
    "  source_concept --relation--> target_concept\n",
    "\n",
    "Rules:\n",
    "- Concepts should be short noun phrases (e.g., \"loss function\", \"gradient descent\").\n",
    "- relation should be a short phrase like \"depends on\", \"is defined as\", \"causes\".\n",
    "- For each edge, include:\n",
    "  - id\n",
    "  - source_concept\n",
    "  - target_concept\n",
    "  - relation\n",
    "  - topic\n",
    "  - source_excerpt\n",
    "  - source_doc_id\n",
    "\n",
    "Output format:\n",
    "Return a JSON object matching this structure:\n",
    "\n",
    "{{\n",
    "  \"mcqs\": [],\n",
    "  \"short_answers\": [],\n",
    "  \"concept_edges\": [\n",
    "    {{\n",
    "      \"id\": \"string\",\n",
    "      \"source_concept\": \"string\",\n",
    "      \"target_concept\": \"string\",\n",
    "      \"relation\": \"string\",\n",
    "      \"topic\": \"string\",\n",
    "      \"source_excerpt\": \"string\",\n",
    "      \"source_doc_id\": \"string\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "984596bf-c490-4b7d-83ee-872e78e64e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MCQ PROMPT PREVIEW ===\n",
      "You are an AI tutor helping a teacher create exam-style multiple-choice questions.\n",
      "\n",
      "Use ONLY the information in the CONTEXT below. Do not invent facts.\n",
      "\n",
      "CONTEXT:\n",
      "[SOURCE_ID: sample_data:page=3:chunk=None]\n",
      "Figure 8.2   Value of  t -ratio of slope coefficient for 1,000 sets of regressions of a non-stationary variable on another independent non- stationary variable 8.1.2 Two Types of Non-Stationarity There are two models that have been frequently used to characterise the non-stationarity, the  random walk model with drift ( 8.1) and the  trend-stationary process  – so called because it is stationar...\n",
      "\n",
      "[SOURCE_ID: sample_data:page=5:chunk=None]\n",
      "some starting value of  y 0 . This is known as the  unit root case , for the root of the characteristic equation would be unity. (3) ϕ  > 1. Now given shocks become more influential as time goes on, since if  ϕ  > 1,  ϕ 3  >  ϕ 2  >  ϕ , etc. This is the  explosive case  which, for the reasons listed above, will not be considered as a plausible description of the data. Going back to the two cha...\n",
      "\n",
      "[SOURCE_ID: sample_data:page=0:chunk=None]\n",
      "8 Modelling Long-Run Relationships in Finance LEARNING OUTCOMES In this chapter, you will learn how to Highlight the problems that may occur if non-stationary data are used in their levels form Test for unit roots Examine whether systems of variables are cointegrated Estimate error correction and vector error correction models Explain the intuition behind Johansen’s test for cointegration Descr...\n",
      "\n",
      "TASK:\n",
      "Generate 3 clear, unambiguous multiple-choice questions about the topic: \"types of non-stationarity\".\n",
      "\n",
      "Rules:\n",
      "- Each question must have exactly 4 options.\n",
      "- Exactly ONE option must be correct.\n",
      "- Options must be mutually exclusive; avoid \"all of the above\".\n",
      "- Tag each question with difficulty: \"easy\", \"medium\", or \"hard\".\n",
      "- For each question, include:\n",
      "  - a unique id string\n",
      "  - the question stem\n",
      "  - the 4 options\n",
      "  - correct_option_index (0, 1, 2, or 3)\n",
      "  - topic (short topic label)\n",
      "  - source\n",
      "\n",
      "\n",
      "=== SHORT-ANSWER PROMPT PREVIEW ===\n",
      "You are an AI tutor generating short-answer questions for students.\n",
      "\n",
      "Use ONLY the information in the CONTEXT below.\n",
      "\n",
      "CONTEXT:\n",
      "[SOURCE_ID: sample_data:page=3:chunk=None]\n",
      "Figure 8.2   Value of  t -ratio of slope coefficient for 1,000 sets of regressions of a non-stationary variable on another independent non- stationary variable 8.1.2 Two Types of Non-Stationarity There are two models that have been frequently used to characterise the non-stationarity, the  random walk model with drift ( 8.1) and the  trend-stationary process  – so called because it is stationar...\n",
      "\n",
      "[SOURCE_ID: sample_data:page=5:chunk=None]\n",
      "some starting value of  y 0 . This is known as the  unit root case , for the root of the characteristic equation would be unity. (3) ϕ  > 1. Now given shocks become more influential as time goes on, since if  ϕ  > 1,  ϕ 3  >  ϕ 2  >  ϕ , etc. This is the  explosive case  which, for the reasons listed above, will not be considered as a plausible description of the data. Going back to \n",
      "\n",
      "\n",
      "=== CONCEPT-MAP PROMPT PREVIEW ===\n",
      "You are an AI assistant extracting concept-map relations from lecture text.\n",
      "\n",
      "Use ONLY the information in the CONTEXT below.\n",
      "\n",
      "CONTEXT:\n",
      "[SOURCE_ID: sample_data:page=3:chunk=None]\n",
      "Figure 8.2   Value of  t -ratio of slope coefficient for 1,000 sets of regressions of a non-stationary variable on another independent non- stationary variable 8.1.2 Two Types of Non-Stationarity There are two models that have been frequently used to characterise the non-stationarity, the  random walk model with drift ( 8.1) and the  trend-stationary process  – so called because it is stationar...\n",
      "\n",
      "[SOURCE_ID: sample_data:page=5:chunk=None]\n",
      "some starting value of  y 0 . This is known as the  unit root case , for the root of the characteristic equation would be unity. (3) ϕ  > 1. Now given shocks become more influential as time goes on, since if  ϕ  > 1,  ϕ 3  >  ϕ 2  >  ϕ , etc. This is the  explosive case  which, for the reasons listed above, will not be considered as a plausible description of the data. Going \n"
     ]
    }
   ],
   "source": [
    "sample_topic = \"types of non-stationarity\"  \n",
    "\n",
    "mcq_prompt = build_mcq_prompt(sample_topic, k_context=3)\n",
    "short_prompt = build_short_answer_prompt(sample_topic, k_context=3)\n",
    "concept_prompt = build_concept_map_prompt(sample_topic, k_context=3)\n",
    "\n",
    "print(\"=== MCQ PROMPT PREVIEW ===\")\n",
    "print(mcq_prompt[:2000]) \n",
    "\n",
    "print(\"\\n\\n=== SHORT-ANSWER PROMPT PREVIEW ===\")\n",
    "print(short_prompt[:1000])\n",
    "\n",
    "print(\"\\n\\n=== CONCEPT-MAP PROMPT PREVIEW ===\")\n",
    "print(concept_prompt[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe7993b-47cf-4d31-b746-83e3ba70064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed MCQ count: 1\n",
      "First MCQ stem: Which of the following best describes a probability distribution?\n",
      "First MCQ correct option index: 0\n"
     ]
    }
   ],
   "source": [
    "fake_json = {\n",
    "    \"mcqs\": [\n",
    "        {\n",
    "            \"id\": \"mcq_1\",\n",
    "            \"stem\": \"Which of the following best describes a probability distribution?\",\n",
    "            \"options\": [\n",
    "                \"A function that assigns probabilities to events\",\n",
    "                \"A table of raw data\",\n",
    "                \"A deterministic algorithm\",\n",
    "                \"A measure of central tendency\"\n",
    "            ],\n",
    "            \"correct_option_index\": 0,\n",
    "            \"difficulty\": \"easy\",\n",
    "            \"topic\": \"probability_distribution\",\n",
    "            \"source_excerpt\": \"A probability distribution assigns probabilities to each possible outcome.\",\n",
    "            \"source_doc_id\": \"sample_data:page=3:chunk=5\"\n",
    "        }\n",
    "    ],\n",
    "    \"short_answers\": [],\n",
    "    \"concept_edges\": []\n",
    "}\n",
    "\n",
    "bundle = QuestionBundle(**fake_json)\n",
    "print(\"Parsed MCQ count:\", len(bundle.mcqs))\n",
    "print(\"First MCQ stem:\", bundle.mcqs[0].stem)\n",
    "print(\"First MCQ correct option index:\", bundle.mcqs[0].correct_option_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
